{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-21</td>\n",
       "      <td>0.224461</td>\n",
       "      <td>0.501282</td>\n",
       "      <td>0.274257</td>\n",
       "      <td>15.7</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>61502</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-22</td>\n",
       "      <td>0.288634</td>\n",
       "      <td>0.496198</td>\n",
       "      <td>0.215168</td>\n",
       "      <td>16.8</td>\n",
       "      <td>17.6</td>\n",
       "      <td>16.6</td>\n",
       "      <td>60975</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-23</td>\n",
       "      <td>0.257223</td>\n",
       "      <td>0.437274</td>\n",
       "      <td>0.305503</td>\n",
       "      <td>17.3</td>\n",
       "      <td>17.6</td>\n",
       "      <td>16.8</td>\n",
       "      <td>49439</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-24</td>\n",
       "      <td>0.235050</td>\n",
       "      <td>0.551573</td>\n",
       "      <td>0.213377</td>\n",
       "      <td>17.5</td>\n",
       "      <td>19.2</td>\n",
       "      <td>15.6</td>\n",
       "      <td>172009</td>\n",
       "      <td>17.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-25</td>\n",
       "      <td>0.231190</td>\n",
       "      <td>0.506552</td>\n",
       "      <td>0.262257</td>\n",
       "      <td>16.9</td>\n",
       "      <td>17.8</td>\n",
       "      <td>15.4</td>\n",
       "      <td>80767</td>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>2019-12-27</td>\n",
       "      <td>0.226849</td>\n",
       "      <td>0.446411</td>\n",
       "      <td>0.326740</td>\n",
       "      <td>7210.8</td>\n",
       "      <td>7293.8</td>\n",
       "      <td>7128.5</td>\n",
       "      <td>718074</td>\n",
       "      <td>7261.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>2019-12-28</td>\n",
       "      <td>0.169157</td>\n",
       "      <td>0.471205</td>\n",
       "      <td>0.359638</td>\n",
       "      <td>7261.9</td>\n",
       "      <td>7375.9</td>\n",
       "      <td>7256.5</td>\n",
       "      <td>610964</td>\n",
       "      <td>7196.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2533</th>\n",
       "      <td>2019-12-29</td>\n",
       "      <td>0.197365</td>\n",
       "      <td>0.523340</td>\n",
       "      <td>0.279295</td>\n",
       "      <td>7321.6</td>\n",
       "      <td>7518.9</td>\n",
       "      <td>7303.0</td>\n",
       "      <td>611687</td>\n",
       "      <td>7199.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>2019-12-30</td>\n",
       "      <td>0.170356</td>\n",
       "      <td>0.481577</td>\n",
       "      <td>0.348067</td>\n",
       "      <td>7397.5</td>\n",
       "      <td>7420.9</td>\n",
       "      <td>7244.1</td>\n",
       "      <td>606110</td>\n",
       "      <td>6967.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>0.198009</td>\n",
       "      <td>0.451574</td>\n",
       "      <td>0.350417</td>\n",
       "      <td>7261.5</td>\n",
       "      <td>7331.0</td>\n",
       "      <td>7167.4</td>\n",
       "      <td>586595</td>\n",
       "      <td>7343.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2536 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  positive   neutral  negative    open    high     low   \n",
       "0     2013-01-21  0.224461  0.501282  0.274257    15.7    17.0    15.6  \\\n",
       "1     2013-01-22  0.288634  0.496198  0.215168    16.8    17.6    16.6   \n",
       "2     2013-01-23  0.257223  0.437274  0.305503    17.3    17.6    16.8   \n",
       "3     2013-01-24  0.235050  0.551573  0.213377    17.5    19.2    15.6   \n",
       "4     2013-01-25  0.231190  0.506552  0.262257    16.9    17.8    15.4   \n",
       "...          ...       ...       ...       ...     ...     ...     ...   \n",
       "2531  2019-12-27  0.226849  0.446411  0.326740  7210.8  7293.8  7128.5   \n",
       "2532  2019-12-28  0.169157  0.471205  0.359638  7261.9  7375.9  7256.5   \n",
       "2533  2019-12-29  0.197365  0.523340  0.279295  7321.6  7518.9  7303.0   \n",
       "2534  2019-12-30  0.170356  0.481577  0.348067  7397.5  7420.9  7244.1   \n",
       "2535  2019-12-31  0.198009  0.451574  0.350417  7261.5  7331.0  7167.4   \n",
       "\n",
       "      volume   close  \n",
       "0      61502    16.9  \n",
       "1      60975    17.4  \n",
       "2      49439    17.9  \n",
       "3     172009    17.8  \n",
       "4      80767    18.7  \n",
       "...      ...     ...  \n",
       "2531  718074  7261.8  \n",
       "2532  610964  7196.4  \n",
       "2533  611687  7199.8  \n",
       "2534  606110  6967.0  \n",
       "2535  586595  7343.1  \n",
       "\n",
       "[2536 rows x 9 columns]"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = '../datasets/consolidated/consolidated.csv'\n",
    "\n",
    "data = pd.read_csv(\n",
    "    filepath_or_buffer=dataset_path,\n",
    ")\n",
    "\n",
    "data['date'] = pd.to_datetime(data['date']).dt.date\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'close'\n",
    "\n",
    "x = data.drop(columns=[target, 'date']).values\n",
    "y = data[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "x = scaler.fit_transform(x)\n",
    "y = scaler.fit_transform(y.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.005927, MAPE: 0.107872\n",
      "Fold 2: RMSE: 0.004217, MAPE: 0.071275\n",
      "Fold 3: RMSE: 0.017937, MAPE: 0.057524\n",
      "Fold 4: RMSE: 0.042225, MAPE: 0.020288\n",
      "Fold 5: RMSE: 0.052780, MAPE: 0.029633\n",
      "\n",
      "Average RMSE: 0.024617\n",
      "Average MAPE: 0.057319\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Definir el modelo de Transformer\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_heads, num_layers, hidden_dim):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.transformer = nn.Transformer(\n",
    "            d_model=input_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            dim_feedforward=hidden_dim,\n",
    "            dropout=0.1,\n",
    "            activation='relu',\n",
    "        )\n",
    "        self.fc = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.transformer(x, x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Definir conjunto de datos personalizado\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "# Crear el modelo de Transformer\n",
    "input_dim = x.shape[1]\n",
    "output_dim = y.shape[1]\n",
    "num_heads = input_dim\n",
    "num_layers = 3\n",
    "hidden_dim = 64\n",
    "\n",
    "# Definir nÃºmero de divisiones para k-fold cross-validation\n",
    "num_splits = 5\n",
    "kf = KFold(n_splits=num_splits, shuffle=False)\n",
    "\n",
    "# Listas para almacenar los resultados de cada fold\n",
    "rmse_list = []\n",
    "mape_list = []\n",
    "\n",
    "# Loop para realizar k-fold cross-validation\n",
    "for fold, (train_indices, test_indices) in enumerate(kf.split(x)):\n",
    "    print(f\"Fold {fold+1}: \", end=\"\")\n",
    "\n",
    "    # Dividir los datos en conjuntos de entrenamiento y prueba para este fold\n",
    "    x_train, x_test = x[train_indices], x[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "    # Crear DataLoader para los datos de entrenamiento\n",
    "    x_train_tensor = torch.from_numpy(x_train).float()\n",
    "    y_train_tensor = torch.from_numpy(y_train).float()\n",
    "    train_dataset = CustomDataset(x_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    # Crear modelo para este fold\n",
    "    model = TransformerModel(\n",
    "        input_dim=input_dim,\n",
    "        output_dim=output_dim,\n",
    "        num_heads=num_heads,\n",
    "        num_layers=num_layers,\n",
    "        hidden_dim=hidden_dim,\n",
    "    )\n",
    "\n",
    "    # Definir funciÃ³n de pÃ©rdida RMSE\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Definir el optimizador\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Entrenamiento del modelo\n",
    "    num_epochs = 200\n",
    "    loss_list = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch_x)\n",
    "            loss = criterion(output, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += np.sqrt(loss.item())\n",
    "\n",
    "    # Evaluar el modelo con los datos de prueba\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x_test_tensor = torch.from_numpy(x_test).float()\n",
    "        y_test_tensor = torch.from_numpy(y_test).float()\n",
    "        output = model(x_test_tensor)\n",
    "        y_pred = output.detach().numpy()\n",
    "\n",
    "    # Calcular el RMSE\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "    # Calcular el MAPE\n",
    "    y_test_original = scaler.inverse_transform(y_test)\n",
    "    y_pred_original = scaler.inverse_transform(y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test_original, y_pred_original)\n",
    "    mape_list.append(mape)\n",
    "\n",
    "    print(f\"RMSE: {rmse:.6f}, MAPE: {mape:.6f}\")\n",
    "\n",
    "# Calcular los promedios de RMSE y MAPE para todos los folds\n",
    "avg_rmse = np.mean(rmse_list)\n",
    "avg_mape = np.mean(mape_list)\n",
    "\n",
    "print(f\"\\nAverage RMSE: {avg_rmse:.6f}\")\n",
    "print(f\"Average MAPE: {avg_mape:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
